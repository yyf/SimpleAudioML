{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a85c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x17324d940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "Processed chunk 1/1\n",
      "Generative stereo audio saved to ../output/stereo_audio_CNN_generated.wav\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, Input\n",
    "\n",
    "# Load mono audio file\n",
    "mono_audio_path = \"../data/mono_audio_16k_short.wav\"  \n",
    "audio, sr = librosa.load(mono_audio_path, sr=None, mono=True)\n",
    "\n",
    "# Normalize audio\n",
    "audio = audio / np.max(np.abs(audio))\n",
    "\n",
    "# Prepare input data for the model\n",
    "# Reshape audio to match input dimensions (batch_size, time_steps, features)\n",
    "audio_input = audio.reshape(1, -1, 1)\n",
    "\n",
    "# Prepare input data for the model - process in smaller chunks\n",
    "CHUNK_SIZE = 8192  # Process audio in smaller segments\n",
    "\n",
    "# Define a simple generative model for upmixing\n",
    "model = Sequential([\n",
    "    Input(shape=(audio_input.shape[1], 1)),  \n",
    "    Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "    Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    Conv1D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "    Flatten(),\n",
    "    Dense(audio_input.shape[1], activation='tanh'),  \n",
    "])\n",
    "\n",
    "# Generate stereo audio using the model\n",
    "# For simplicity, we use random weights (no training)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# stereo_output = model.predict(audio_input)\n",
    "\n",
    "# Process audio in chunks\n",
    "stereo_chunks = []\n",
    "for i in range(0, len(audio), CHUNK_SIZE):\n",
    "    chunk = audio[i:i+CHUNK_SIZE]\n",
    "    chunk_input = chunk.reshape(1, -1, 1)\n",
    "    \n",
    "    # Generate stereo for this chunk\n",
    "    chunk_output = model.predict(chunk_input)\n",
    "    stereo_chunks.append(chunk_output[0])\n",
    "    \n",
    "    # Optional: Print progress\n",
    "    print(f\"Processed chunk {i//CHUNK_SIZE + 1}/{(len(audio) + CHUNK_SIZE - 1)//CHUNK_SIZE}\")\n",
    "\n",
    "# Combine all chunks\n",
    "stereo_output = np.concatenate(stereo_chunks, axis=0)\n",
    "\n",
    "# Reshape the output to (num_samples, 2) for stereo\n",
    "stereo_output = stereo_output.reshape(-1, 2)\n",
    "\n",
    "# Extract left and right channels\n",
    "left_channel = stereo_output[:, 0]\n",
    "right_channel = stereo_output[:, 1]\n",
    "\n",
    "# Normalize channels to avoid clipping\n",
    "left_channel = left_channel / np.max(np.abs(left_channel))\n",
    "right_channel = right_channel / np.max(np.abs(right_channel))\n",
    "\n",
    "# Combine channels into stereo\n",
    "stereo_audio = np.vstack((left_channel, right_channel)).T\n",
    "\n",
    "# Save the stereo audio file\n",
    "stereo_audio_path = \"../output/stereo_audio_CNN_generated.wav\" \n",
    "sf.write(stereo_audio_path, stereo_audio, sr)\n",
    "\n",
    "print(f\"Generative stereo audio saved to {stereo_audio_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
